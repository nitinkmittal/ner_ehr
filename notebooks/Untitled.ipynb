{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fp = \"../data/train/100039.txt\"\n",
    "ann_fp = \"../data/train/100039.ann\"\n",
    "\n",
    "# text_fp = \"dummy.txt\"\n",
    "# ann_fp = \"dummy.ann\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = None\n",
    "with open(text_fp, \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = None\n",
    "with open(ann_fp) as f:\n",
    "    ann = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import CustomAnnotationParser, CustomTokenParser\n",
    "from ner_ehr.tokenizers import ScispacyTokenizer, SplitTokenizer, _validate_token_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ner_ehr.tokenizers.ScispacyTokenizer at 0x2b692f069f98>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SplitTokenizer(validate_token_idxs=True, splitlines=True)\n",
    "tokenizer = ScispacyTokenizer(validate_token_idxs=True) \n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_parser = CustomAnnotationParser(tokenizer=tokenizer)\n",
    "annotations = ann_parser(annotations_fp=ann_fp, record_fp=text_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_parser = CustomTokenParser(tokenizer=tokenizer,)\n",
    "tokens = token_parser.parse(record_fp=text_fp, annotations=annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5766"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner_ehr.data.ehr import EHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr = EHR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr.to_csv_tokens_with_annotations(tokens, annotations, fp=\"blah.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(token='Admission', start_idx=0, end_idx=9),\n",
       " Token(token='Date', start_idx=10, end_idx=14),\n",
       " Token(token=':', start_idx=14, end_idx=15),\n",
       " Token(token='[', start_idx=17, end_idx=18),\n",
       " Token(token='*', start_idx=18, end_idx=19),\n",
       " Token(token='*', start_idx=19, end_idx=20),\n",
       " Token(token='2174', start_idx=20, end_idx=24),\n",
       " Token(token='-', start_idx=24, end_idx=25),\n",
       " Token(token='4', start_idx=25, end_idx=26),\n",
       " Token(token='-', start_idx=26, end_idx=27),\n",
       " Token(token='18', start_idx=27, end_idx=29),\n",
       " Token(token='*', start_idx=29, end_idx=30),\n",
       " Token(token='*', start_idx=30, end_idx=31),\n",
       " Token(token=']', start_idx=31, end_idx=32),\n",
       " Token(token='Discharge', start_idx=46, end_idx=55),\n",
       " Token(token='Date', start_idx=56, end_idx=60),\n",
       " Token(token=':', start_idx=60, end_idx=61),\n",
       " Token(token='[', start_idx=64, end_idx=65),\n",
       " Token(token='*', start_idx=65, end_idx=66),\n",
       " Token(token='*', start_idx=66, end_idx=67),\n",
       " Token(token='2174', start_idx=67, end_idx=71),\n",
       " Token(token='-', start_idx=71, end_idx=72),\n",
       " Token(token='5', start_idx=72, end_idx=73),\n",
       " Token(token='-', start_idx=73, end_idx=74),\n",
       " Token(token='17', start_idx=74, end_idx=76),\n",
       " Token(token='*', start_idx=76, end_idx=77),\n",
       " Token(token='*', start_idx=77, end_idx=78),\n",
       " Token(token=']', start_idx=78, end_idx=79),\n",
       " Token(token='Date', start_idx=81, end_idx=85),\n",
       " Token(token='of', start_idx=86, end_idx=88),\n",
       " Token(token='Birth', start_idx=89, end_idx=94),\n",
       " Token(token=':', start_idx=94, end_idx=95),\n",
       " Token(token='[', start_idx=97, end_idx=98),\n",
       " Token(token='*', start_idx=98, end_idx=99),\n",
       " Token(token='*', start_idx=99, end_idx=100),\n",
       " Token(token='2135', start_idx=100, end_idx=104),\n",
       " Token(token='-', start_idx=104, end_idx=105),\n",
       " Token(token='11', start_idx=105, end_idx=107),\n",
       " Token(token='-', start_idx=107, end_idx=108),\n",
       " Token(token='15', start_idx=108, end_idx=110),\n",
       " Token(token='*', start_idx=110, end_idx=111),\n",
       " Token(token='*', start_idx=111, end_idx=112),\n",
       " Token(token=']', start_idx=112, end_idx=113),\n",
       " Token(token='Sex', start_idx=126, end_idx=129),\n",
       " Token(token=':', start_idx=129, end_idx=130),\n",
       " Token(token='F', start_idx=133, end_idx=134),\n",
       " Token(token='Service', start_idx=136, end_idx=143),\n",
       " Token(token=':', start_idx=143, end_idx=144),\n",
       " Token(token='MEDICINE', start_idx=145, end_idx=153),\n",
       " Token(token='Allergies', start_idx=155, end_idx=164),\n",
       " Token(token=':', start_idx=164, end_idx=165),\n",
       " Token(token='Prochlorperazine', start_idx=166, end_idx=182),\n",
       " Token(token='/', start_idx=183, end_idx=184),\n",
       " Token(token='Heparin', start_idx=185, end_idx=192),\n",
       " Token(token='Agents', start_idx=193, end_idx=199),\n",
       " Token(token='Attending:[**First', start_idx=201, end_idx=219),\n",
       " Token(token='Name3', start_idx=220, end_idx=225),\n",
       " Token(token='(', start_idx=226, end_idx=227),\n",
       " Token(token='LF', start_idx=227, end_idx=229),\n",
       " Token(token=')', start_idx=229, end_idx=230),\n",
       " Token(token='3918', start_idx=231, end_idx=235),\n",
       " Token(token='*', start_idx=235, end_idx=236),\n",
       " Token(token='*', start_idx=236, end_idx=237),\n",
       " Token(token=']', start_idx=237, end_idx=238),\n",
       " Token(token='Chief', start_idx=239, end_idx=244),\n",
       " Token(token='Complaint', start_idx=245, end_idx=254),\n",
       " Token(token=':', start_idx=254, end_idx=255),\n",
       " Token(token='Abdominal', start_idx=256, end_idx=265),\n",
       " Token(token='Pain', start_idx=266, end_idx=270),\n",
       " Token(token='Major', start_idx=272, end_idx=277),\n",
       " Token(token='Surgical', start_idx=278, end_idx=286),\n",
       " Token(token='or', start_idx=287, end_idx=289),\n",
       " Token(token='Invasive', start_idx=290, end_idx=298),\n",
       " Token(token='Procedure', start_idx=299, end_idx=308),\n",
       " Token(token=':', start_idx=308, end_idx=309),\n",
       " Token(token='Upper', start_idx=310, end_idx=315),\n",
       " Token(token='GI', start_idx=316, end_idx=318),\n",
       " Token(token='series', start_idx=319, end_idx=325),\n",
       " Token(token='with', start_idx=326, end_idx=330),\n",
       " Token(token='small', start_idx=331, end_idx=336),\n",
       " Token(token='bowel', start_idx=337, end_idx=342),\n",
       " Token(token='follow', start_idx=343, end_idx=349),\n",
       " Token(token='through', start_idx=350, end_idx=357),\n",
       " Token(token='Right', start_idx=358, end_idx=363),\n",
       " Token(token='heart', start_idx=364, end_idx=369),\n",
       " Token(token='catheterization', start_idx=370, end_idx=385),\n",
       " Token(token='IR', start_idx=386, end_idx=388),\n",
       " Token(token='guided', start_idx=389, end_idx=395),\n",
       " Token(token='paracentesis', start_idx=396, end_idx=408),\n",
       " Token(token='History', start_idx=411, end_idx=418),\n",
       " Token(token='of', start_idx=419, end_idx=421),\n",
       " Token(token='Present', start_idx=422, end_idx=429),\n",
       " Token(token='Illness', start_idx=430, end_idx=437),\n",
       " Token(token=':', start_idx=437, end_idx=438),\n",
       " Token(token='38', start_idx=439, end_idx=441),\n",
       " Token(token='yo', start_idx=442, end_idx=444),\n",
       " Token(token='F', start_idx=445, end_idx=446),\n",
       " Token(token='w/', start_idx=447, end_idx=449),\n",
       " Token(token='h/o', start_idx=450, end_idx=453),\n",
       " Token(token='ALL', start_idx=454, end_idx=457),\n",
       " Token(token='in', start_idx=458, end_idx=460),\n",
       " Token(token='remission', start_idx=461, end_idx=470),\n",
       " Token(token='s/p', start_idx=471, end_idx=474),\n",
       " Token(token='cord', start_idx=475, end_idx=479),\n",
       " Token(token='transplant', start_idx=480, end_idx=490),\n",
       " Token(token='in', start_idx=491, end_idx=493),\n",
       " Token(token='[', start_idx=494, end_idx=495),\n",
       " Token(token='*', start_idx=495, end_idx=496),\n",
       " Token(token='*', start_idx=496, end_idx=497),\n",
       " Token(token='1', start_idx=497, end_idx=498),\n",
       " Token(token='-', start_idx=498, end_idx=499),\n",
       " Token(token='13', start_idx=499, end_idx=501),\n",
       " Token(token='*', start_idx=501, end_idx=502),\n",
       " Token(token='*', start_idx=502, end_idx=503),\n",
       " Token(token=']', start_idx=503, end_idx=504),\n",
       " Token(token=',', start_idx=504, end_idx=505),\n",
       " Token(token='anthracycline', start_idx=506, end_idx=519),\n",
       " Token(token='-induced', start_idx=519, end_idx=527),\n",
       " Token(token='cardiomyopathy', start_idx=528, end_idx=542),\n",
       " Token(token='(', start_idx=543, end_idx=544),\n",
       " Token(token='EF', start_idx=544, end_idx=546),\n",
       " Token(token='15', start_idx=547, end_idx=549),\n",
       " Token(token='-', start_idx=549, end_idx=550),\n",
       " Token(token='20', start_idx=550, end_idx=552),\n",
       " Token(token='%', start_idx=552, end_idx=553),\n",
       " Token(token='[', start_idx=554, end_idx=555),\n",
       " Token(token='*', start_idx=555, end_idx=556),\n",
       " Token(token='*', start_idx=556, end_idx=557),\n",
       " Token(token='1', start_idx=557, end_idx=558),\n",
       " Token(token='-', start_idx=558, end_idx=559),\n",
       " Token(token='14', start_idx=559, end_idx=561),\n",
       " Token(token='*', start_idx=561, end_idx=562),\n",
       " Token(token='*', start_idx=562, end_idx=563),\n",
       " Token(token=']', start_idx=563, end_idx=564),\n",
       " Token(token=')', start_idx=564, end_idx=565),\n",
       " Token(token='and', start_idx=566, end_idx=569),\n",
       " Token(token='recurrent', start_idx=570, end_idx=579),\n",
       " Token(token='nausea', start_idx=580, end_idx=586),\n",
       " Token(token='and', start_idx=587, end_idx=590),\n",
       " Token(token='vomiting', start_idx=591, end_idx=599),\n",
       " Token(token='who', start_idx=600, end_idx=603),\n",
       " Token(token='presents', start_idx=604, end_idx=612),\n",
       " Token(token='with', start_idx=613, end_idx=617),\n",
       " Token(token='abdominal', start_idx=618, end_idx=627),\n",
       " Token(token='pain', start_idx=628, end_idx=632),\n",
       " Token(token=',', start_idx=632, end_idx=633),\n",
       " Token(token='N/V', start_idx=634, end_idx=637),\n",
       " Token(token='x1', start_idx=638, end_idx=640),\n",
       " Token(token='week', start_idx=641, end_idx=645),\n",
       " Token(token='Of', start_idx=647, end_idx=649),\n",
       " Token(token='note', start_idx=650, end_idx=654),\n",
       " Token(token=',', start_idx=654, end_idx=655),\n",
       " Token(token='the', start_idx=656, end_idx=659),\n",
       " Token(token='pt', start_idx=660, end_idx=662),\n",
       " Token(token='was', start_idx=663, end_idx=666),\n",
       " Token(token='admitted', start_idx=667, end_idx=675),\n",
       " Token(token='here', start_idx=676, end_idx=680),\n",
       " Token(token='from', start_idx=681, end_idx=685),\n",
       " Token(token='[', start_idx=686, end_idx=687),\n",
       " Token(token='*', start_idx=687, end_idx=688),\n",
       " Token(token='*', start_idx=688, end_idx=689),\n",
       " Token(token='Date', start_idx=689, end_idx=693),\n",
       " Token(token='range', start_idx=694, end_idx=699),\n",
       " Token(token='(', start_idx=700, end_idx=701),\n",
       " Token(token='1', start_idx=701, end_idx=702),\n",
       " Token(token=')', start_idx=702, end_idx=703),\n",
       " Token(token='*', start_idx=704, end_idx=705),\n",
       " Token(token='*', start_idx=705, end_idx=706),\n",
       " Token(token=']', start_idx=706, end_idx=707),\n",
       " Token(token='with', start_idx=708, end_idx=712),\n",
       " Token(token='nausea', start_idx=713, end_idx=719),\n",
       " Token(token='and', start_idx=720, end_idx=723),\n",
       " Token(token='vomitting', start_idx=724, end_idx=733),\n",
       " Token(token='of', start_idx=734, end_idx=736),\n",
       " Token(token='unclear', start_idx=737, end_idx=744),\n",
       " Token(token='etiology', start_idx=745, end_idx=753),\n",
       " Token(token='.', start_idx=753, end_idx=754),\n",
       " Token(token='When', start_idx=755, end_idx=759),\n",
       " Token(token='discharged', start_idx=760, end_idx=770),\n",
       " Token(token=',', start_idx=770, end_idx=771),\n",
       " Token(token='she', start_idx=772, end_idx=775),\n",
       " Token(token='was', start_idx=776, end_idx=779),\n",
       " Token(token='tolerating', start_idx=780, end_idx=790),\n",
       " Token(token='good', start_idx=791, end_idx=795),\n",
       " Token(token='PO', start_idx=796, end_idx=798),\n",
       " Token(token='and', start_idx=799, end_idx=802),\n",
       " Token(token='had', start_idx=803, end_idx=806),\n",
       " Token(token='planned', start_idx=807, end_idx=814),\n",
       " Token(token='f/u', start_idx=815, end_idx=818),\n",
       " Token(token='with', start_idx=819, end_idx=823),\n",
       " Token(token='neuro', start_idx=824, end_idx=829),\n",
       " Token(token='for', start_idx=830, end_idx=833),\n",
       " Token(token='?', start_idx=834, end_idx=835),\n",
       " Token(token='abdominal', start_idx=836, end_idx=845),\n",
       " Token(token='migraine', start_idx=846, end_idx=854),\n",
       " Token(token='and', start_idx=855, end_idx=858),\n",
       " Token(token='GI', start_idx=859, end_idx=861),\n",
       " Token(token='for', start_idx=862, end_idx=865),\n",
       " Token(token='possible', start_idx=866, end_idx=874),\n",
       " Token(token='other', start_idx=875, end_idx=880),\n",
       " Token(token='contributing', start_idx=881, end_idx=893),\n",
       " Token(token='factors', start_idx=894, end_idx=901),\n",
       " Token(token='including', start_idx=902, end_idx=911),\n",
       " Token(token='food', start_idx=912, end_idx=916),\n",
       " Token(token='sensitivities', start_idx=917, end_idx=930),\n",
       " Token(token='and', start_idx=931, end_idx=934),\n",
       " Token(token='gastroparesis', start_idx=935, end_idx=948),\n",
       " Token(token='.', start_idx=948, end_idx=949),\n",
       " Token(token='In', start_idx=951, end_idx=953),\n",
       " Token(token='the', start_idx=954, end_idx=957),\n",
       " Token(token='ED', start_idx=958, end_idx=960),\n",
       " Token(token=',', start_idx=960, end_idx=961),\n",
       " Token(token='VS', start_idx=962, end_idx=964),\n",
       " Token(token=':', start_idx=964, end_idx=965),\n",
       " Token(token='98.8', start_idx=966, end_idx=970),\n",
       " Token(token='94', start_idx=971, end_idx=973),\n",
       " Token(token='138/100', start_idx=974, end_idx=981),\n",
       " Token(token='16', start_idx=982, end_idx=984),\n",
       " Token(token='100', start_idx=985, end_idx=988),\n",
       " Token(token='%', start_idx=988, end_idx=989),\n",
       " Token(token='and', start_idx=990, end_idx=993),\n",
       " Token(token='[', start_idx=994, end_idx=995),\n",
       " Token(token='*', start_idx=995, end_idx=996),\n",
       " Token(token='*', start_idx=996, end_idx=997),\n",
       " Token(token='10', start_idx=997, end_idx=999),\n",
       " Token(token='-', start_idx=999, end_idx=1000),\n",
       " Token(token='15', start_idx=1000, end_idx=1002),\n",
       " Token(token='*', start_idx=1002, end_idx=1003),\n",
       " Token(token='*', start_idx=1003, end_idx=1004),\n",
       " Token(token=']', start_idx=1004, end_idx=1005),\n",
       " Token(token='pain', start_idx=1006, end_idx=1010),\n",
       " Token(token='.', start_idx=1010, end_idx=1011),\n",
       " Token(token='CT', start_idx=1012, end_idx=1014),\n",
       " Token(token='A/P', start_idx=1015, end_idx=1018),\n",
       " Token(token='showed', start_idx=1019, end_idx=1025),\n",
       " Token(token='a', start_idx=1026, end_idx=1027),\n",
       " Token(token='small', start_idx=1028, end_idx=1033),\n",
       " Token(token='umbilical', start_idx=1034, end_idx=1043),\n",
       " Token(token='hernia', start_idx=1044, end_idx=1050),\n",
       " Token(token=';', start_idx=1050, end_idx=1051),\n",
       " Token(token='interval', start_idx=1052, end_idx=1060),\n",
       " Token(token='increase', start_idx=1061, end_idx=1069),\n",
       " Token(token='in', start_idx=1070, end_idx=1072),\n",
       " Token(token='size', start_idx=1073, end_idx=1077),\n",
       " Token(token='and', start_idx=1078, end_idx=1081),\n",
       " Token(token='mild', start_idx=1082, end_idx=1086),\n",
       " Token(token='fat', start_idx=1087, end_idx=1090),\n",
       " Token(token='stranding', start_idx=1091, end_idx=1100),\n",
       " Token(token='and', start_idx=1101, end_idx=1104),\n",
       " Token(token='interval', start_idx=1105, end_idx=1113),\n",
       " Token(token='increase', start_idx=1114, end_idx=1122),\n",
       " Token(token='in', start_idx=1123, end_idx=1125),\n",
       " Token(token='ascites', start_idx=1126, end_idx=1133),\n",
       " Token(token='compared', start_idx=1134, end_idx=1142),\n",
       " Token(token='to', start_idx=1143, end_idx=1145),\n",
       " Token(token='recent', start_idx=1146, end_idx=1152),\n",
       " Token(token='prior', start_idx=1153, end_idx=1158),\n",
       " Token(token='imaging', start_idx=1159, end_idx=1166),\n",
       " Token(token='.', start_idx=1166, end_idx=1167),\n",
       " Token(token='WBC', start_idx=1169, end_idx=1172),\n",
       " Token(token='12.4', start_idx=1173, end_idx=1177),\n",
       " Token(token='with', start_idx=1178, end_idx=1182),\n",
       " Token(token='no', start_idx=1183, end_idx=1185),\n",
       " Token(token='left', start_idx=1186, end_idx=1190),\n",
       " Token(token='shift', start_idx=1191, end_idx=1196),\n",
       " Token(token=',', start_idx=1196, end_idx=1197),\n",
       " Token(token='bili', start_idx=1198, end_idx=1202),\n",
       " Token(token='2.1', start_idx=1203, end_idx=1206),\n",
       " Token(token='up', start_idx=1207, end_idx=1209),\n",
       " Token(token='from', start_idx=1210, end_idx=1214),\n",
       " Token(token='1.1', start_idx=1215, end_idx=1218),\n",
       " Token(token=',', start_idx=1218, end_idx=1219),\n",
       " Token(token='Cr', start_idx=1220, end_idx=1222),\n",
       " Token(token='2.7', start_idx=1223, end_idx=1226),\n",
       " Token(token='up', start_idx=1227, end_idx=1229),\n",
       " Token(token='from', start_idx=1230, end_idx=1234),\n",
       " Token(token='2.3', start_idx=1235, end_idx=1238),\n",
       " Token(token='.', start_idx=1238, end_idx=1239),\n",
       " Token(token='Surgery', start_idx=1241, end_idx=1248),\n",
       " Token(token='was', start_idx=1249, end_idx=1252),\n",
       " Token(token='consulted', start_idx=1253, end_idx=1262),\n",
       " Token(token='give', start_idx=1263, end_idx=1267),\n",
       " Token(token='CT', start_idx=1268, end_idx=1270),\n",
       " Token(token='finding', start_idx=1271, end_idx=1278),\n",
       " Token(token='and', start_idx=1279, end_idx=1282),\n",
       " Token(token='did', start_idx=1283, end_idx=1286),\n",
       " Token(token='not', start_idx=1287, end_idx=1290),\n",
       " Token(token='feel', start_idx=1291, end_idx=1295),\n",
       " Token(token='there', start_idx=1296, end_idx=1301),\n",
       " Token(token='was', start_idx=1302, end_idx=1305),\n",
       " Token(token='an', start_idx=1306, end_idx=1308),\n",
       " Token(token='indication', start_idx=1309, end_idx=1319),\n",
       " Token(token='for', start_idx=1320, end_idx=1323),\n",
       " Token(token='surgery', start_idx=1324, end_idx=1331),\n",
       " Token(token='.', start_idx=1331, end_idx=1332),\n",
       " Token(token='She', start_idx=1333, end_idx=1336),\n",
       " Token(token='received', start_idx=1337, end_idx=1345),\n",
       " Token(token='iv', start_idx=1346, end_idx=1348),\n",
       " Token(token='zofran', start_idx=1349, end_idx=1355),\n",
       " Token(token='and', start_idx=1356, end_idx=1359),\n",
       " Token(token='morphine', start_idx=1360, end_idx=1368),\n",
       " Token(token='4', start_idx=1369, end_idx=1370),\n",
       " Token(token='mg', start_idx=1370, end_idx=1372),\n",
       " Token(token='iv', start_idx=1373, end_idx=1375),\n",
       " Token(token='and', start_idx=1376, end_idx=1379),\n",
       " Token(token='1L', start_idx=1380, end_idx=1382),\n",
       " Token(token='IVF', start_idx=1383, end_idx=1386),\n",
       " Token(token='.', start_idx=1386, end_idx=1387),\n",
       " Token(token='On', start_idx=1389, end_idx=1391),\n",
       " Token(token='arrival', start_idx=1392, end_idx=1399),\n",
       " Token(token='to', start_idx=1400, end_idx=1402),\n",
       " Token(token='the', start_idx=1403, end_idx=1406),\n",
       " Token(token='floor', start_idx=1407, end_idx=1412),\n",
       " Token(token=',', start_idx=1412, end_idx=1413),\n",
       " Token(token='patient', start_idx=1414, end_idx=1421),\n",
       " Token(token='reports', start_idx=1422, end_idx=1429),\n",
       " Token(token='[', start_idx=1430, end_idx=1431),\n",
       " Token(token='*', start_idx=1431, end_idx=1432),\n",
       " Token(token='*', start_idx=1432, end_idx=1433),\n",
       " Token(token='11', start_idx=1433, end_idx=1435),\n",
       " Token(token='-', start_idx=1435, end_idx=1436),\n",
       " Token(token='14', start_idx=1436, end_idx=1438),\n",
       " Token(token='*', start_idx=1438, end_idx=1439),\n",
       " Token(token='*', start_idx=1439, end_idx=1440),\n",
       " Token(token=']', start_idx=1440, end_idx=1441),\n",
       " Token(token='total', start_idx=1442, end_idx=1447),\n",
       " Token(token='body', start_idx=1448, end_idx=1452),\n",
       " Token(token='pain', start_idx=1453, end_idx=1457),\n",
       " Token(token='and', start_idx=1458, end_idx=1461),\n",
       " Token(token='nausea', start_idx=1462, end_idx=1468),\n",
       " Token(token='.', start_idx=1468, end_idx=1469),\n",
       " Token(token='She', start_idx=1471, end_idx=1474),\n",
       " Token(token='has', start_idx=1475, end_idx=1478),\n",
       " Token(token='had', start_idx=1479, end_idx=1482),\n",
       " Token(token='ice', start_idx=1483, end_idx=1486),\n",
       " Token(token='chips', start_idx=1487, end_idx=1492),\n",
       " Token(token='today', start_idx=1493, end_idx=1498),\n",
       " Token(token='but', start_idx=1499, end_idx=1502),\n",
       " Token(token='threw', start_idx=1503, end_idx=1508),\n",
       " Token(token='them', start_idx=1509, end_idx=1513),\n",
       " Token(token='up', start_idx=1514, end_idx=1516),\n",
       " Token(token='in', start_idx=1517, end_idx=1519),\n",
       " Token(token='the', start_idx=1520, end_idx=1523),\n",
       " Token(token='ED', start_idx=1524, end_idx=1526),\n",
       " Token(token='.', start_idx=1526, end_idx=1527),\n",
       " Token(token='Review', start_idx=1529, end_idx=1535),\n",
       " Token(token='of', start_idx=1536, end_idx=1538),\n",
       " Token(token='Systems', start_idx=1539, end_idx=1546),\n",
       " Token(token=':', start_idx=1546, end_idx=1547),\n",
       " Token(token='(', start_idx=1548, end_idx=1549),\n",
       " Token(token='+', start_idx=1549, end_idx=1550),\n",
       " Token(token=')', start_idx=1550, end_idx=1551),\n",
       " Token(token='Per', start_idx=1552, end_idx=1555),\n",
       " Token(token='HPI', start_idx=1556, end_idx=1559),\n",
       " Token(token='(', start_idx=1560, end_idx=1561),\n",
       " Token(token='-', start_idx=1561, end_idx=1562),\n",
       " Token(token=')', start_idx=1562, end_idx=1563),\n",
       " Token(token='Review', start_idx=1564, end_idx=1570),\n",
       " Token(token='of', start_idx=1571, end_idx=1573),\n",
       " Token(token='Systems', start_idx=1574, end_idx=1581),\n",
       " Token(token=':', start_idx=1581, end_idx=1582),\n",
       " Token(token='Denies', start_idx=1583, end_idx=1589),\n",
       " Token(token='fevers', start_idx=1590, end_idx=1596),\n",
       " Token(token=',', start_idx=1596, end_idx=1597),\n",
       " Token(token='chest', start_idx=1598, end_idx=1603),\n",
       " Token(token='pain', start_idx=1604, end_idx=1608),\n",
       " Token(token=',', start_idx=1608, end_idx=1609),\n",
       " Token(token='SOB', start_idx=1610, end_idx=1613),\n",
       " Token(token=',', start_idx=1613, end_idx=1614),\n",
       " Token(token='diarrhea', start_idx=1615, end_idx=1623),\n",
       " Token(token=',', start_idx=1623, end_idx=1624),\n",
       " Token(token='constipation', start_idx=1625, end_idx=1637),\n",
       " Token(token=',', start_idx=1637, end_idx=1638),\n",
       " Token(token='dysuria', start_idx=1639, end_idx=1646),\n",
       " Token(token=',', start_idx=1646, end_idx=1647),\n",
       " Token(token='HA', start_idx=1648, end_idx=1650),\n",
       " Token(token=',', start_idx=1650, end_idx=1651),\n",
       " Token(token='change', start_idx=1652, end_idx=1658),\n",
       " Token(token='in', start_idx=1659, end_idx=1661),\n",
       " Token(token='vision', start_idx=1662, end_idx=1668),\n",
       " Token(token='or', start_idx=1669, end_idx=1671),\n",
       " Token(token='dizziness', start_idx=1672, end_idx=1681),\n",
       " Token(token='.', start_idx=1681, end_idx=1682),\n",
       " Token(token='Past', start_idx=1685, end_idx=1689),\n",
       " Token(token='Medical', start_idx=1690, end_idx=1697),\n",
       " Token(token='History', start_idx=1698, end_idx=1705),\n",
       " Token(token=':', start_idx=1705, end_idx=1706),\n",
       " Token(token='ONCOLOGIC', start_idx=1707, end_idx=1716),\n",
       " Token(token='HISTORY', start_idx=1717, end_idx=1724),\n",
       " Token(token=':', start_idx=1724, end_idx=1725),\n",
       " Token(token='ALL', start_idx=1726, end_idx=1729),\n",
       " Token(token=':', start_idx=1729, end_idx=1730),\n",
       " Token(token='-', start_idx=1731, end_idx=1732),\n",
       " Token(token='initially', start_idx=1733, end_idx=1742),\n",
       " Token(token='presented', start_idx=1743, end_idx=1752),\n",
       " Token(token='in', start_idx=1753, end_idx=1755),\n",
       " Token(token='[', start_idx=1756, end_idx=1757),\n",
       " Token(token='*', start_idx=1757, end_idx=1758),\n",
       " Token(token='*', start_idx=1758, end_idx=1759),\n",
       " Token(token='2172', start_idx=1759, end_idx=1763),\n",
       " Token(token='-', start_idx=1763, end_idx=1764),\n",
       " Token(token='8', start_idx=1764, end_idx=1765),\n",
       " Token(token='-', start_idx=1765, end_idx=1766),\n",
       " Token(token='5', start_idx=1766, end_idx=1767),\n",
       " Token(token='*', start_idx=1767, end_idx=1768),\n",
       " Token(token='*', start_idx=1768, end_idx=1769),\n",
       " Token(token=']', start_idx=1769, end_idx=1770),\n",
       " Token(token='right', start_idx=1771, end_idx=1776),\n",
       " Token(token='chest', start_idx=1777, end_idx=1782),\n",
       " Token(token='and', start_idx=1783, end_idx=1786),\n",
       " Token(token='right', start_idx=1787, end_idx=1792),\n",
       " Token(token='upper', start_idx=1793, end_idx=1798),\n",
       " Token(token='extremity', start_idx=1799, end_idx=1808),\n",
       " Token(token='pain', start_idx=1809, end_idx=1813),\n",
       " Token(token='and', start_idx=1814, end_idx=1817),\n",
       " Token(token='paresthesias', start_idx=1818, end_idx=1830),\n",
       " Token(token='and', start_idx=1831, end_idx=1834),\n",
       " Token(token='visual', start_idx=1835, end_idx=1841),\n",
       " Token(token='blurriness', start_idx=1842, end_idx=1852),\n",
       " Token(token='.', start_idx=1852, end_idx=1853),\n",
       " Token(token='WBC', start_idx=1854, end_idx=1857),\n",
       " Token(token='149,000', start_idx=1858, end_idx=1865),\n",
       " Token(token=';', start_idx=1865, end_idx=1866),\n",
       " Token(token='received', start_idx=1867, end_idx=1875),\n",
       " Token(token='leukapheresis', start_idx=1876, end_idx=1889),\n",
       " Token(token=',', start_idx=1889, end_idx=1890),\n",
       " Token(token='started', start_idx=1891, end_idx=1898),\n",
       " Token(token='on', start_idx=1899, end_idx=1901),\n",
       " Token(token='hydroxyurea', start_idx=1902, end_idx=1913),\n",
       " Token(token='.', start_idx=1913, end_idx=1914),\n",
       " Token(token=\"Dx'ed\", start_idx=1915, end_idx=1920),\n",
       " Token(token='with', start_idx=1921, end_idx=1925),\n",
       " Token(token='precursor', start_idx=1926, end_idx=1935),\n",
       " Token(token='B-cell', start_idx=1936, end_idx=1942),\n",
       " Token(token='ALL', start_idx=1943, end_idx=1946),\n",
       " Token(token='.', start_idx=1946, end_idx=1947),\n",
       " Token(token='-', start_idx=1948, end_idx=1949),\n",
       " Token(token='underwent', start_idx=1950, end_idx=1959),\n",
       " Token(token='phase', start_idx=1960, end_idx=1965),\n",
       " Token(token='I', start_idx=1966, end_idx=1967),\n",
       " Token(token='induction', start_idx=1968, end_idx=1977),\n",
       " Token(token='with', start_idx=1978, end_idx=1982),\n",
       " Token(token='daunorubicin', start_idx=1983, end_idx=1995),\n",
       " Token(token=',', start_idx=1995, end_idx=1996),\n",
       " Token(token='vincristine', start_idx=1997, end_idx=2008),\n",
       " Token(token=',', start_idx=2008, end_idx=2009),\n",
       " Token(token='dexamethasone', start_idx=2010, end_idx=2023),\n",
       " Token(token=',', start_idx=2023, end_idx=2024),\n",
       " Token(token='L-asparaginase', start_idx=2025, end_idx=2039),\n",
       " Token(token=',', start_idx=2039, end_idx=2040),\n",
       " Token(token='MTX', start_idx=2041, end_idx=2044),\n",
       " Token(token=';', start_idx=2044, end_idx=2045),\n",
       " Token(token='phase', start_idx=2046, end_idx=2051),\n",
       " Token(token='II', start_idx=2052, end_idx=2054),\n",
       " Token(token='with', start_idx=2055, end_idx=2059),\n",
       " Token(token='cyclophosphamide', start_idx=2060, end_idx=2076),\n",
       " Token(token=',', start_idx=2076, end_idx=2077),\n",
       " Token(token='cytarabine', start_idx=2078, end_idx=2088),\n",
       " Token(token=',', start_idx=2088, end_idx=2089),\n",
       " Token(token='mercaptopurine', start_idx=2090, end_idx=2104),\n",
       " Token(token=',', start_idx=2104, end_idx=2105),\n",
       " Token(token='MTX', start_idx=2106, end_idx=2109),\n",
       " Token(token='-', start_idx=2110, end_idx=2111),\n",
       " Token(token='Bone', start_idx=2112, end_idx=2116),\n",
       " Token(token='Marrow', start_idx=2117, end_idx=2123),\n",
       " Token(token='Aspirate/Biopsy', start_idx=2124, end_idx=2139),\n",
       " Token(token='on', start_idx=2140, end_idx=2142),\n",
       " Token(token='[', start_idx=2143, end_idx=2144),\n",
       " Token(token='*', start_idx=2144, end_idx=2145),\n",
       " Token(token='*', start_idx=2145, end_idx=2146),\n",
       " Token(token='2172', start_idx=2146, end_idx=2150),\n",
       " Token(token='-', start_idx=2150, end_idx=2151),\n",
       " Token(token='10', start_idx=2151, end_idx=2153),\n",
       " Token(token='-', start_idx=2153, end_idx=2154),\n",
       " Token(token='26', start_idx=2154, end_idx=2156),\n",
       " Token(token='*', start_idx=2156, end_idx=2157),\n",
       " Token(token='*', start_idx=2157, end_idx=2158),\n",
       " Token(token=']', start_idx=2158, end_idx=2159),\n",
       " Token(token='showed', start_idx=2160, end_idx=2166),\n",
       " Token(token='no', start_idx=2167, end_idx=2169),\n",
       " Token(token='morphologic', start_idx=2170, end_idx=2181),\n",
       " Token(token='evidence', start_idx=2183, end_idx=2191),\n",
       " Token(token='of', start_idx=2192, end_idx=2194),\n",
       " Token(token='residual', start_idx=2195, end_idx=2203),\n",
       " Token(token='leukemia', start_idx=2204, end_idx=2212),\n",
       " Token(token='-', start_idx=2213, end_idx=2214),\n",
       " Token(token='underwent', start_idx=2215, end_idx=2224),\n",
       " Token(token='allo', start_idx=2225, end_idx=2229),\n",
       " Token(token='double', start_idx=2230, end_idx=2236),\n",
       " Token(token='cord', start_idx=2237, end_idx=2241),\n",
       " Token(token='blood', start_idx=2242, end_idx=2247),\n",
       " Token(token='SCT', start_idx=2248, end_idx=2251),\n",
       " Token(token='[', start_idx=2252, end_idx=2253),\n",
       " Token(token='*', start_idx=2253, end_idx=2254),\n",
       " Token(token='*', start_idx=2254, end_idx=2255),\n",
       " Token(token='2173', start_idx=2255, end_idx=2259),\n",
       " Token(token='-', start_idx=2259, end_idx=2260),\n",
       " Token(token='1', start_idx=2260, end_idx=2261),\n",
       " Token(token='-', start_idx=2261, end_idx=2262),\n",
       " Token(token='11', start_idx=2262, end_idx=2264),\n",
       " Token(token='*', start_idx=2264, end_idx=2265),\n",
       " Token(token='*', start_idx=2265, end_idx=2266),\n",
       " Token(token=']', start_idx=2266, end_idx=2267),\n",
       " Token(token=',', start_idx=2267, end_idx=2268),\n",
       " Token(token='course', start_idx=2269, end_idx=2275),\n",
       " Token(token='complicated', start_idx=2276, end_idx=2287),\n",
       " Token(token='by', start_idx=2288, end_idx=2290),\n",
       " Token(token='neutropenic', start_idx=2291, end_idx=2302),\n",
       " Token(token='fever', start_idx=2303, end_idx=2308),\n",
       " Token(token='and', start_idx=2309, end_idx=2312),\n",
       " Token(token='acute', start_idx=2313, end_idx=2318),\n",
       " Token(token='skin', start_idx=2319, end_idx=2323),\n",
       " Token(token='GVHD', start_idx=2324, end_idx=2328),\n",
       " Token(token='OTHER', start_idx=2330, end_idx=2335),\n",
       " Token(token='MEDICAL', start_idx=2336, end_idx=2343),\n",
       " Token(token='HISTORY', start_idx=2344, end_idx=2351),\n",
       " Token(token=':', start_idx=2351, end_idx=2352),\n",
       " Token(token='-', start_idx=2353, end_idx=2354),\n",
       " Token(token='Embolic', start_idx=2355, end_idx=2362),\n",
       " Token(token='stroke', start_idx=2363, end_idx=2369),\n",
       " Token(token='in', start_idx=2370, end_idx=2372),\n",
       " Token(token='[', start_idx=2373, end_idx=2374),\n",
       " Token(token='*', start_idx=2374, end_idx=2375),\n",
       " Token(token='*', start_idx=2375, end_idx=2376),\n",
       " Token(token='3-/2174', start_idx=2376, end_idx=2383),\n",
       " Token(token='*', start_idx=2383, end_idx=2384),\n",
       " Token(token='*', start_idx=2384, end_idx=2385),\n",
       " Token(token=']', start_idx=2385, end_idx=2386),\n",
       " Token(token='on', start_idx=2387, end_idx=2389),\n",
       " Token(token='coumadin', start_idx=2390, end_idx=2398),\n",
       " Token(token='-', start_idx=2399, end_idx=2400),\n",
       " Token(token='Cardiomyopathy', start_idx=2401, end_idx=2415),\n",
       " Token(token='due', start_idx=2416, end_idx=2419),\n",
       " Token(token='to', start_idx=2420, end_idx=2422),\n",
       " Token(token='early', start_idx=2423, end_idx=2428),\n",
       " Token(token='anthracycline', start_idx=2429, end_idx=2442),\n",
       " Token(token='-related', start_idx=2442, end_idx=2450),\n",
       " Token(token='cardiotoxicity', start_idx=2451, end_idx=2465),\n",
       " Token(token='[', start_idx=2466, end_idx=2467),\n",
       " Token(token='*', start_idx=2467, end_idx=2468),\n",
       " Token(token='*', start_idx=2468, end_idx=2469),\n",
       " Token(token='10/2172', start_idx=2469, end_idx=2476),\n",
       " Token(token='*', start_idx=2476, end_idx=2477),\n",
       " Token(token='*', start_idx=2477, end_idx=2478),\n",
       " Token(token=']', start_idx=2478, end_idx=2479),\n",
       " Token(token='-', start_idx=2480, end_idx=2481),\n",
       " Token(token='Chronic', start_idx=2482, end_idx=2489),\n",
       " Token(token='kidney', start_idx=2490, end_idx=2496),\n",
       " Token(token='disease', start_idx=2497, end_idx=2504),\n",
       " Token(token='stage', start_idx=2505, end_idx=2510),\n",
       " Token(token='III/IV', start_idx=2511, end_idx=2517),\n",
       " Token(token=',', start_idx=2517, end_idx=2518),\n",
       " Token(token='baseline', start_idx=2519, end_idx=2527),\n",
       " Token(token='creatinine', start_idx=2528, end_idx=2538),\n",
       " Token(token='~2.0', start_idx=2539, end_idx=2543),\n",
       " Token(token='-', start_idx=2543, end_idx=2544),\n",
       " Token(token='2.2', start_idx=2544, end_idx=2547),\n",
       " Token(token='-', start_idx=2548, end_idx=2549),\n",
       " Token(token='Asthma', start_idx=2550, end_idx=2556),\n",
       " Token(token='-', start_idx=2557, end_idx=2558),\n",
       " Token(token='HTN', start_idx=2559, end_idx=2562),\n",
       " Token(token='-', start_idx=2563, end_idx=2564),\n",
       " Token(token='Cervical', start_idx=2565, end_idx=2573),\n",
       " Token(token='Intraepithelial', start_idx=2574, end_idx=2589),\n",
       " Token(token='neoplasia', start_idx=2590, end_idx=2599),\n",
       " Token(token='-', start_idx=2600, end_idx=2601),\n",
       " Token(token='C-section', start_idx=2602, end_idx=2611),\n",
       " Token(token='in', start_idx=2612, end_idx=2614),\n",
       " Token(token='[', start_idx=2615, end_idx=2616),\n",
       " Token(token='*', start_idx=2616, end_idx=2617),\n",
       " Token(token='*', start_idx=2617, end_idx=2618),\n",
       " Token(token='2165', start_idx=2618, end_idx=2622),\n",
       " Token(token='*', start_idx=2622, end_idx=2623),\n",
       " Token(token='*', start_idx=2623, end_idx=2624),\n",
       " Token(token=']', start_idx=2624, end_idx=2625),\n",
       " Token(token='Social', start_idx=2628, end_idx=2634),\n",
       " Token(token='History', start_idx=2635, end_idx=2642),\n",
       " Token(token=':', start_idx=2642, end_idx=2643),\n",
       " Token(token='Smoke', start_idx=2644, end_idx=2649),\n",
       " Token(token=':', start_idx=2649, end_idx=2650),\n",
       " Token(token='never', start_idx=2651, end_idx=2656),\n",
       " Token(token='EtOH', start_idx=2657, end_idx=2661),\n",
       " Token(token=':', start_idx=2661, end_idx=2662),\n",
       " Token(token='Occasional', start_idx=2663, end_idx=2673),\n",
       " Token(token='in', start_idx=2674, end_idx=2676),\n",
       " Token(token='past', start_idx=2677, end_idx=2681),\n",
       " Token(token=',', start_idx=2681, end_idx=2682),\n",
       " Token(token='none', start_idx=2683, end_idx=2687),\n",
       " Token(token='currently', start_idx=2688, end_idx=2697),\n",
       " Token(token='Drugs', start_idx=2698, end_idx=2703),\n",
       " Token(token=':', start_idx=2703, end_idx=2704),\n",
       " Token(token='Never', start_idx=2705, end_idx=2710),\n",
       " Token(token='Lives/works', start_idx=2711, end_idx=2722),\n",
       " Token(token=':', start_idx=2722, end_idx=2723),\n",
       " Token(token='Single', start_idx=2724, end_idx=2730),\n",
       " Token(token=',', start_idx=2730, end_idx=2731),\n",
       " Token(token='has', start_idx=2732, end_idx=2735),\n",
       " Token(token='two', start_idx=2736, end_idx=2739),\n",
       " Token(token='children', start_idx=2740, end_idx=2748),\n",
       " Token(token='(', start_idx=2749, end_idx=2750),\n",
       " Token(token='ages', start_idx=2750, end_idx=2754),\n",
       " Token(token='7', start_idx=2755, end_idx=2756),\n",
       " Token(token='and', start_idx=2757, end_idx=2760),\n",
       " Token(token='18', start_idx=2761, end_idx=2763),\n",
       " Token(token=')', start_idx=2763, end_idx=2764),\n",
       " Token(token='.', start_idx=2764, end_idx=2765),\n",
       " Token(token='Lives', start_idx=2766, end_idx=2771),\n",
       " Token(token='in', start_idx=2772, end_idx=2774),\n",
       " Token(token='[', start_idx=2775, end_idx=2776),\n",
       " Token(token='*', start_idx=2776, end_idx=2777),\n",
       " Token(token='*', start_idx=2777, end_idx=2778),\n",
       " Token(token='Location', start_idx=2778, end_idx=2786),\n",
       " Token(token='686', start_idx=2787, end_idx=2790),\n",
       " Token(token='*', start_idx=2790, end_idx=2791),\n",
       " Token(token='*', start_idx=2791, end_idx=2792),\n",
       " Token(token=']', start_idx=2792, end_idx=2793),\n",
       " Token(token='.', start_idx=2793, end_idx=2794),\n",
       " Token(token='Was', start_idx=2795, end_idx=2798),\n",
       " Token(token='previously', start_idx=2799, end_idx=2809),\n",
       " Token(token='employed', start_idx=2810, end_idx=2818),\n",
       " Token(token='at', start_idx=2819, end_idx=2821),\n",
       " Token(token='[', start_idx=2822, end_idx=2823),\n",
       " Token(token='*', start_idx=2823, end_idx=2824),\n",
       " Token(token='*', start_idx=2824, end_idx=2825),\n",
       " Token(token='Company', start_idx=2825, end_idx=2832),\n",
       " Token(token='59330', start_idx=2833, end_idx=2838),\n",
       " Token(token='*', start_idx=2838, end_idx=2839),\n",
       " Token(token='*', start_idx=2839, end_idx=2840),\n",
       " Token(token=']', start_idx=2840, end_idx=2841),\n",
       " Token(token=',', start_idx=2841, end_idx=2842),\n",
       " Token(token='has', start_idx=2843, end_idx=2846),\n",
       " Token(token=\"n't\", start_idx=2846, end_idx=2849),\n",
       " Token(token='been', start_idx=2850, end_idx=2854),\n",
       " Token(token='working', start_idx=2855, end_idx=2862),\n",
       " Token(token='since', start_idx=2863, end_idx=2868),\n",
       " Token(token='being', start_idx=2869, end_idx=2874),\n",
       " Token(token='diagnosed', start_idx=2875, end_idx=2884),\n",
       " Token(token='with', start_idx=2885, end_idx=2889),\n",
       " Token(token='ALL', start_idx=2890, end_idx=2893),\n",
       " Token(token='in', start_idx=2894, end_idx=2896),\n",
       " Token(token='[', start_idx=2897, end_idx=2898),\n",
       " Token(token='*', start_idx=2898, end_idx=2899),\n",
       " Token(token='*', start_idx=2899, end_idx=2900),\n",
       " Token(token='2172', start_idx=2900, end_idx=2904),\n",
       " Token(token='-', start_idx=2904, end_idx=2905),\n",
       " Token(token='8', start_idx=2905, end_idx=2906),\n",
       " Token(token='-', start_idx=2906, end_idx=2907),\n",
       " Token(token='5', start_idx=2907, end_idx=2908),\n",
       " Token(token='*', start_idx=2908, end_idx=2909),\n",
       " Token(token='*', start_idx=2909, end_idx=2910),\n",
       " Token(token=']', start_idx=2910, end_idx=2911),\n",
       " Token(token='.', start_idx=2911, end_idx=2912),\n",
       " Token(token='Family', start_idx=2915, end_idx=2921),\n",
       " Token(token='History', start_idx=2922, end_idx=2929),\n",
       " Token(token=':', start_idx=2929, end_idx=2930),\n",
       " Token(token='Mother', start_idx=2931, end_idx=2937),\n",
       " Token(token='with', start_idx=2938, end_idx=2942),\n",
       " Token(token='gastric', start_idx=2943, end_idx=2950),\n",
       " Token(token='cancer', start_idx=2951, end_idx=2957),\n",
       " Token(token=',', start_idx=2957, end_idx=2958),\n",
       " Token(token='passed', start_idx=2959, end_idx=2965),\n",
       " Token(token='at', start_idx=2966, end_idx=2968),\n",
       " Token(token='the', start_idx=2969, end_idx=2972),\n",
       " Token(token='age', start_idx=2973, end_idx=2976),\n",
       " Token(token='of', start_idx=2977, end_idx=2979),\n",
       " Token(token='40', start_idx=2980, end_idx=2982),\n",
       " Token(token='Father', start_idx=2983, end_idx=2989),\n",
       " Token(token='with', start_idx=2990, end_idx=2994),\n",
       " Token(token='HTN', start_idx=2995, end_idx=2998),\n",
       " Token(token='.', start_idx=2998, end_idx=2999),\n",
       " Token(token='Physical', start_idx=3002, end_idx=3010),\n",
       " Token(token='Exam', start_idx=3011, end_idx=3015),\n",
       " Token(token=':', start_idx=3015, end_idx=3016),\n",
       " Token(token='VS', start_idx=3017, end_idx=3019),\n",
       " Token(token=':', start_idx=3019, end_idx=3020),\n",
       " Token(token='98', start_idx=3021, end_idx=3023),\n",
       " Token(token='145/76', start_idx=3024, end_idx=3030),\n",
       " Token(token='87', start_idx=3031, end_idx=3033),\n",
       " Token(token='15', start_idx=3034, end_idx=3036),\n",
       " Token(token='100', start_idx=3037, end_idx=3040),\n",
       " Token(token='%', start_idx=3040, end_idx=3041),\n",
       " Token(token='RA', start_idx=3042, end_idx=3044),\n",
       " Token(token='GEN', start_idx=3045, end_idx=3048),\n",
       " Token(token=':', start_idx=3048, end_idx=3049),\n",
       " Token(token='well', start_idx=3050, end_idx=3054),\n",
       " Token(token='appearing', start_idx=3055, end_idx=3064),\n",
       " Token(token='F', start_idx=3065, end_idx=3066),\n",
       " Token(token='in', start_idx=3067, end_idx=3069),\n",
       " Token(token='NAD', start_idx=3070, end_idx=3073),\n",
       " Token(token='HEENT', start_idx=3074, end_idx=3079),\n",
       " Token(token=':', start_idx=3079, end_idx=3080),\n",
       " Token(token='slight', start_idx=3081, end_idx=3087),\n",
       " Token(token='dry', start_idx=3088, end_idx=3091),\n",
       " Token(token='MM', start_idx=3092, end_idx=3094),\n",
       " Token(token=',', start_idx=3094, end_idx=3095),\n",
       " Token(token='sclera', start_idx=3096, end_idx=3102),\n",
       " Token(token='anicteric', start_idx=3103, end_idx=3112),\n",
       " Token(token=',', start_idx=3112, end_idx=3113),\n",
       " Token(token='PERRL', start_idx=3114, end_idx=3119),\n",
       " Token(token='Cards', start_idx=3120, end_idx=3125),\n",
       " Token(token=':', start_idx=3125, end_idx=3126),\n",
       " Token(token='RR', start_idx=3127, end_idx=3129),\n",
       " Token(token='S1/S2', start_idx=3130, end_idx=3135),\n",
       " Token(token='normal', start_idx=3136, end_idx=3142),\n",
       " Token(token='.', start_idx=3142, end_idx=3143),\n",
       " Token(token='prominent', start_idx=3144, end_idx=3153),\n",
       " Token(token='S3', start_idx=3154, end_idx=3156),\n",
       " Token(token='Pulm', start_idx=3157, end_idx=3161),\n",
       " Token(token=':', start_idx=3161, end_idx=3162),\n",
       " Token(token='CTAB', start_idx=3163, end_idx=3167),\n",
       " Token(token='Abd', start_idx=3168, end_idx=3171),\n",
       " Token(token=':', start_idx=3171, end_idx=3172),\n",
       " Token(token='Hyperactive', start_idx=3173, end_idx=3184),\n",
       " Token(token='BS', start_idx=3185, end_idx=3187),\n",
       " Token(token='.', start_idx=3187, end_idx=3188),\n",
       " Token(token='Initially', start_idx=3190, end_idx=3199),\n",
       " Token(token='soft', start_idx=3200, end_idx=3204),\n",
       " Token(token='when', start_idx=3205, end_idx=3209),\n",
       " Token(token='palpating', start_idx=3210, end_idx=3219),\n",
       " Token(token='with', start_idx=3220, end_idx=3224),\n",
       " Token(token='stethoscope', start_idx=3225, end_idx=3236),\n",
       " Token(token='over', start_idx=3237, end_idx=3241),\n",
       " Token(token='all', start_idx=3242, end_idx=3245),\n",
       " Token(token='4', start_idx=3246, end_idx=3247),\n",
       " Token(token='quadrants', start_idx=3248, end_idx=3257),\n",
       " Token(token='then', start_idx=3258, end_idx=3262),\n",
       " Token(token='suddenly', start_idx=3263, end_idx=3271),\n",
       " Token(token='exquisitely', start_idx=3272, end_idx=3283),\n",
       " Token(token='tender', start_idx=3284, end_idx=3290),\n",
       " Token(token='on', start_idx=3291, end_idx=3293),\n",
       " Token(token='right', start_idx=3294, end_idx=3299),\n",
       " Token(token='.', start_idx=3299, end_idx=3300),\n",
       " Token(token='No', start_idx=3302, end_idx=3304),\n",
       " Token(token='guarding', start_idx=3305, end_idx=3313),\n",
       " Token(token='initially', start_idx=3314, end_idx=3323),\n",
       " Token(token='.', start_idx=3323, end_idx=3324),\n",
       " Token(token='Unable', start_idx=3326, end_idx=3332),\n",
       " Token(token='to', start_idx=3333, end_idx=3335),\n",
       " Token(token='assess', start_idx=3336, end_idx=3342),\n",
       " Token(token='for', start_idx=3343, end_idx=3346),\n",
       " Token(token='HSM', start_idx=3347, end_idx=3350),\n",
       " Token(token='.', start_idx=3350, end_idx=3351),\n",
       " Token(token='Extremities', start_idx=3352, end_idx=3363),\n",
       " Token(token=':', start_idx=3363, end_idx=3364),\n",
       " Token(token='wwp', start_idx=3365, end_idx=3368),\n",
       " Token(token=',', start_idx=3368, end_idx=3369),\n",
       " Token(token='no', start_idx=3370, end_idx=3372),\n",
       " Token(token='edema', start_idx=3373, end_idx=3378),\n",
       " Token(token='.', start_idx=3378, end_idx=3379),\n",
       " Token(token='PTs', start_idx=3380, end_idx=3383),\n",
       " Token(token='2', start_idx=3384, end_idx=3385),\n",
       " Token(token='+', start_idx=3385, end_idx=3386),\n",
       " Token(token='.', start_idx=3386, end_idx=3387),\n",
       " Token(token='Neuro', start_idx=3388, end_idx=3393),\n",
       " Token(token=':', start_idx=3393, end_idx=3394),\n",
       " Token(token='CNs', start_idx=3395, end_idx=3398),\n",
       " Token(token='II-XII', start_idx=3399, end_idx=3405),\n",
       " Token(token='grossly', start_idx=3406, end_idx=3413),\n",
       " Token(token='intact', start_idx=3414, end_idx=3420),\n",
       " Token(token='.', start_idx=3420, end_idx=3421),\n",
       " Token(token='normal', start_idx=3422, end_idx=3428),\n",
       " Token(token='gait', start_idx=3429, end_idx=3433),\n",
       " Token(token='Psych', start_idx=3434, end_idx=3439),\n",
       " Token(token=':', start_idx=3439, end_idx=3440),\n",
       " Token(token='overly', start_idx=3442, end_idx=3448),\n",
       " Token(token='dramatic', start_idx=3449, end_idx=3457),\n",
       " Token(token='affect', start_idx=3458, end_idx=3464),\n",
       " Token(token='Pertinent', start_idx=3467, end_idx=3476),\n",
       " Token(token='Results', start_idx=3477, end_idx=3484),\n",
       " Token(token=':', start_idx=3484, end_idx=3485),\n",
       " Token(token='On', start_idx=3486, end_idx=3488),\n",
       " Token(token='admission', start_idx=3489, end_idx=3498),\n",
       " Token(token=':', start_idx=3498, end_idx=3499),\n",
       " Token(token='[', start_idx=3500, end_idx=3501),\n",
       " Token(token='*', start_idx=3501, end_idx=3502),\n",
       " Token(token='*', start_idx=3502, end_idx=3503),\n",
       " Token(token='2174', start_idx=3503, end_idx=3507),\n",
       " Token(token='-', start_idx=3507, end_idx=3508),\n",
       " Token(token='4', start_idx=3508, end_idx=3509),\n",
       " Token(token='-', start_idx=3509, end_idx=3510),\n",
       " Token(token='18', start_idx=3510, end_idx=3512),\n",
       " Token(token='*', start_idx=3512, end_idx=3513),\n",
       " Token(token='*', start_idx=3513, end_idx=3514),\n",
       " Token(token=']', start_idx=3514, end_idx=3515),\n",
       " Token(token='02:00PM', start_idx=3516, end_idx=3523),\n",
       " Token(token='BLOOD', start_idx=3524, end_idx=3529),\n",
       " Token(token='WBC-12.4', start_idx=3530, end_idx=3538),\n",
       " Token(token='*', start_idx=3538, end_idx=3539),\n",
       " Token(token='RBC-3.78', start_idx=3540, end_idx=3548),\n",
       " Token(token='*', start_idx=3548, end_idx=3549),\n",
       " Token(token='Hgb-11.4', start_idx=3550, end_idx=3558),\n",
       " Token(token='*', start_idx=3558, end_idx=3559),\n",
       " Token(token='Hct-36.3', start_idx=3560, end_idx=3568),\n",
       " Token(token='MCV-96', start_idx=3569, end_idx=3575),\n",
       " Token(token='MCH-30.2', start_idx=3576, end_idx=3584),\n",
       " Token(token='MCHC-31.4', start_idx=3585, end_idx=3594),\n",
       " Token(token='RDW-16.5', start_idx=3595, end_idx=3603),\n",
       " Token(token='*', start_idx=3603, end_idx=3604),\n",
       " Token(token='Plt', start_idx=3605, end_idx=3608),\n",
       " Token(token='Ct-212', start_idx=3609, end_idx=3615),\n",
       " Token(token='[', start_idx=3616, end_idx=3617),\n",
       " Token(token='*', start_idx=3617, end_idx=3618),\n",
       " Token(token='*', start_idx=3618, end_idx=3619),\n",
       " Token(token='2174', start_idx=3619, end_idx=3623),\n",
       " Token(token='-', start_idx=3623, end_idx=3624),\n",
       " Token(token='4', start_idx=3624, end_idx=3625),\n",
       " Token(token='-', start_idx=3625, end_idx=3626),\n",
       " Token(token='18', start_idx=3626, end_idx=3628),\n",
       " Token(token='*', start_idx=3628, end_idx=3629),\n",
       " Token(token='*', start_idx=3629, end_idx=3630),\n",
       " Token(token=']', start_idx=3630, end_idx=3631),\n",
       " Token(token='02:00PM', start_idx=3632, end_idx=3639),\n",
       " Token(token='BLOOD', start_idx=3640, end_idx=3645),\n",
       " Token(token='Neuts-67.3', start_idx=3646, end_idx=3656),\n",
       " Token(token='Lymphs-23.8', start_idx=3657, end_idx=3668),\n",
       " Token(token='Monos-7.7', start_idx=3669, end_idx=3678),\n",
       " Token(token='Eos-0.5', start_idx=3679, end_idx=3686),\n",
       " Token(token='Baso-0.7', start_idx=3687, end_idx=3695),\n",
       " Token(token='[', start_idx=3696, end_idx=3697),\n",
       " Token(token='*', start_idx=3697, end_idx=3698),\n",
       " Token(token='*', start_idx=3698, end_idx=3699),\n",
       " Token(token='2174', start_idx=3699, end_idx=3703),\n",
       " Token(token='-', start_idx=3703, end_idx=3704),\n",
       " Token(token='4', start_idx=3704, end_idx=3705),\n",
       " Token(token='-', start_idx=3705, end_idx=3706),\n",
       " Token(token='18', start_idx=3706, end_idx=3708),\n",
       " Token(token='*', start_idx=3708, end_idx=3709),\n",
       " Token(token='*', start_idx=3709, end_idx=3710),\n",
       " Token(token=']', start_idx=3710, end_idx=3711),\n",
       " Token(token='04:30PM', start_idx=3712, end_idx=3719),\n",
       " Token(token='BLOOD', start_idx=3720, end_idx=3725),\n",
       " Token(token='PT-30.1', start_idx=3726, end_idx=3733),\n",
       " Token(token='*', start_idx=3733, end_idx=3734),\n",
       " Token(token='PTT-29.4', start_idx=3735, end_idx=3743),\n",
       " Token(token='INR(PT)-3.0', start_idx=3744, end_idx=3755),\n",
       " Token(token='*', start_idx=3755, end_idx=3756),\n",
       " Token(token='[', start_idx=3757, end_idx=3758),\n",
       " Token(token='*', start_idx=3758, end_idx=3759),\n",
       " Token(token='*', start_idx=3759, end_idx=3760),\n",
       " Token(token='2174', start_idx=3760, end_idx=3764),\n",
       " Token(token='-', start_idx=3764, end_idx=3765),\n",
       " Token(token='4', start_idx=3765, end_idx=3766),\n",
       " Token(token='-', start_idx=3766, end_idx=3767),\n",
       " Token(token='18', start_idx=3767, end_idx=3769),\n",
       " Token(token='*', start_idx=3769, end_idx=3770),\n",
       " Token(token='*', start_idx=3770, end_idx=3771),\n",
       " Token(token=']', start_idx=3771, end_idx=3772),\n",
       " Token(token='02:00PM', start_idx=3773, end_idx=3780),\n",
       " Token(token='BLOOD', start_idx=3781, end_idx=3786),\n",
       " Token(token='UreaN-30', start_idx=3787, end_idx=3795),\n",
       " Token(token='*', start_idx=3795, end_idx=3796),\n",
       " Token(token='Creat-2.7', start_idx=3797, end_idx=3806),\n",
       " Token(token='*', start_idx=3806, end_idx=3807),\n",
       " Token(token='Na-142', start_idx=3808, end_idx=3814),\n",
       " Token(token='K-4.8', start_idx=3815, end_idx=3820),\n",
       " Token(token='Cl-99', start_idx=3821, end_idx=3826),\n",
       " Token(token='HCO3', start_idx=3827, end_idx=3831),\n",
       " Token(token='-', start_idx=3831, end_idx=3832),\n",
       " Token(token='31', start_idx=3832, end_idx=3834),\n",
       " Token(token='AnGap-17', start_idx=3835, end_idx=3843),\n",
       " Token(token='[', start_idx=3844, end_idx=3845),\n",
       " Token(token='*', start_idx=3845, end_idx=3846),\n",
       " Token(token='*', start_idx=3846, end_idx=3847),\n",
       " Token(token='2174', start_idx=3847, end_idx=3851),\n",
       " Token(token='-', start_idx=3851, end_idx=3852),\n",
       " Token(token='4', start_idx=3852, end_idx=3853),\n",
       " Token(token='-', start_idx=3853, end_idx=3854),\n",
       " Token(token='18', start_idx=3854, end_idx=3856),\n",
       " Token(token='*', start_idx=3856, end_idx=3857),\n",
       " Token(token='*', start_idx=3857, end_idx=3858),\n",
       " Token(token=']', start_idx=3858, end_idx=3859),\n",
       " Token(token='02:00PM', start_idx=3860, end_idx=3867),\n",
       " Token(token='BLOOD', start_idx=3868, end_idx=3873),\n",
       " Token(token='ALT-15', start_idx=3874, end_idx=3880),\n",
       " Token(token='AST-18', start_idx=3881, end_idx=3887),\n",
       " Token(token='AlkPhos-127', start_idx=3888, end_idx=3899),\n",
       " Token(token='*', start_idx=3899, end_idx=3900),\n",
       " Token(token='TotBili-2.1', start_idx=3901, end_idx=3912),\n",
       " Token(token='*', start_idx=3912, end_idx=3913),\n",
       " Token(token='[', start_idx=3914, end_idx=3915),\n",
       " Token(token='*', start_idx=3915, end_idx=3916),\n",
       " Token(token='*', start_idx=3916, end_idx=3917),\n",
       " Token(token='2174', start_idx=3917, end_idx=3921),\n",
       " Token(token='-', start_idx=3921, end_idx=3922),\n",
       " Token(token='4', start_idx=3922, end_idx=3923),\n",
       " Token(token='-', start_idx=3923, end_idx=3924),\n",
       " Token(token='18', start_idx=3924, end_idx=3926),\n",
       " Token(token='*', start_idx=3926, end_idx=3927),\n",
       " Token(token='*', start_idx=3927, end_idx=3928),\n",
       " Token(token=']', start_idx=3928, end_idx=3929),\n",
       " Token(token='02:00PM', start_idx=3930, end_idx=3937),\n",
       " Token(token='BLOOD', start_idx=3938, end_idx=3943),\n",
       " Token(token='Lipase-63', start_idx=3944, end_idx=3953),\n",
       " Token(token='*', start_idx=3953, end_idx=3954),\n",
       " Token(token='[', start_idx=3955, end_idx=3956),\n",
       " Token(token='*', start_idx=3956, end_idx=3957),\n",
       " Token(token='*', start_idx=3957, end_idx=3958),\n",
       " Token(token='2174', start_idx=3958, end_idx=3962),\n",
       " Token(token='-', start_idx=3962, end_idx=3963),\n",
       " Token(token='4', start_idx=3963, end_idx=3964),\n",
       " Token(token='-', start_idx=3964, end_idx=3965),\n",
       " Token(token='18', start_idx=3965, end_idx=3967),\n",
       " Token(token='*', start_idx=3967, end_idx=3968),\n",
       " Token(token='*', start_idx=3968, end_idx=3969),\n",
       " Token(token=']', start_idx=3969, end_idx=3970),\n",
       " Token(token='02:00PM', start_idx=3971, end_idx=3978),\n",
       " Token(token='BLOOD', start_idx=3979, end_idx=3984),\n",
       " Token(token='cTropnT-<0.01', start_idx=3985, end_idx=3998),\n",
       " Token(token='[', start_idx=3999, end_idx=4000),\n",
       " Token(token='*', start_idx=4000, end_idx=4001),\n",
       " Token(token='*', start_idx=4001, end_idx=4002),\n",
       " Token(token='2174', start_idx=4002, end_idx=4006),\n",
       " Token(token='-', start_idx=4006, end_idx=4007),\n",
       " Token(token='4', start_idx=4007, end_idx=4008),\n",
       " Token(token='-', start_idx=4008, end_idx=4009),\n",
       " Token(token='18', start_idx=4009, end_idx=4011),\n",
       " Token(token='*', start_idx=4011, end_idx=4012),\n",
       " Token(token='*', start_idx=4012, end_idx=4013),\n",
       " Token(token=']', start_idx=4013, end_idx=4014),\n",
       " Token(token='02:00PM', start_idx=4015, end_idx=4022),\n",
       " Token(token='BLOOD', start_idx=4023, end_idx=4028),\n",
       " Token(token='Albumin-3.8', start_idx=4029, end_idx=4040),\n",
       " Token(token='Calcium-9.3', start_idx=4041, end_idx=4052),\n",
       " Token(token='Phos-4.8', start_idx=4053, end_idx=4061),\n",
       " Token(token='*', start_idx=4061, end_idx=4062),\n",
       " Token(token='Mg-2.0', start_idx=4063, end_idx=4069),\n",
       " Token(token='On', start_idx=4071, end_idx=4073),\n",
       " Token(token='discharge', start_idx=4074, end_idx=4083),\n",
       " Token(token=':', start_idx=4083, end_idx=4084),\n",
       " Token(token='[', start_idx=4085, end_idx=4086),\n",
       " Token(token='*', start_idx=4086, end_idx=4087),\n",
       " Token(token='*', start_idx=4087, end_idx=4088),\n",
       " Token(token='2174', start_idx=4088, end_idx=4092),\n",
       " Token(token='-', start_idx=4092, end_idx=4093),\n",
       " Token(token='5', start_idx=4093, end_idx=4094),\n",
       " Token(token='-', start_idx=4094, end_idx=4095),\n",
       " Token(token='17', start_idx=4095, end_idx=4097),\n",
       " Token(token='*', start_idx=4097, end_idx=4098),\n",
       " Token(token='*', start_idx=4098, end_idx=4099),\n",
       " Token(token=']', start_idx=4099, end_idx=4100),\n",
       " Token(token='12:00AM', start_idx=4101, end_idx=4108),\n",
       " Token(token='BLOOD', start_idx=4109, end_idx=4114),\n",
       " Token(token='WBC-19.1', start_idx=4115, end_idx=4123),\n",
       " Token(token='*', start_idx=4123, end_idx=4124),\n",
       " Token(token='RBC-3.86', start_idx=4125, end_idx=4133),\n",
       " Token(token='*', start_idx=4133, end_idx=4134),\n",
       " Token(token='Hgb-11.3', start_idx=4135, end_idx=4143),\n",
       " Token(token='*', start_idx=4143, end_idx=4144),\n",
       " Token(token='Hct-37.7', start_idx=4145, end_idx=4153),\n",
       " Token(token='MCV-98', start_idx=4154, end_idx=4160),\n",
       " Token(token='MCH-29.3', start_idx=4161, end_idx=4169),\n",
       " Token(token='MCHC-30.0', start_idx=4170, end_idx=4179),\n",
       " Token(token='*', start_idx=4179, end_idx=4180),\n",
       " Token(token='RDW-17.8', start_idx=4181, end_idx=4189),\n",
       " Token(token='*', start_idx=4189, end_idx=4190),\n",
       " Token(token='Plt', start_idx=4191, end_idx=4194),\n",
       " Token(token='Ct-419', start_idx=4195, end_idx=4201),\n",
       " Token(token='[', start_idx=4202, end_idx=4203),\n",
       " Token(token='*', start_idx=4203, end_idx=4204),\n",
       " Token(token='*', start_idx=4204, end_idx=4205),\n",
       " Token(token='2174', start_idx=4205, end_idx=4209),\n",
       " Token(token='-', start_idx=4209, end_idx=4210),\n",
       " Token(token='5', start_idx=4210, end_idx=4211),\n",
       " Token(token='-', start_idx=4211, end_idx=4212),\n",
       " Token(token='17', start_idx=4212, end_idx=4214),\n",
       " Token(token='*', start_idx=4214, end_idx=4215),\n",
       " Token(token='*', start_idx=4215, end_idx=4216),\n",
       " Token(token=']', start_idx=4216, end_idx=4217),\n",
       " Token(token='12:00AM', start_idx=4218, end_idx=4225),\n",
       " Token(token='BLOOD', start_idx=4226, end_idx=4231),\n",
       " Token(token='Neuts-81.3', start_idx=4232, end_idx=4242),\n",
       " Token(token='*', start_idx=4242, end_idx=4243),\n",
       " Token(token='Lymphs-11.4', start_idx=4244, end_idx=4255),\n",
       " Token(token='*', start_idx=4255, end_idx=4256),\n",
       " Token(token='Monos-6.9', start_idx=4257, end_idx=4266),\n",
       " Token(token='Eos-0.1', start_idx=4267, end_idx=4274),\n",
       " Token(token='Baso-0.3', start_idx=4275, end_idx=4283),\n",
       " Token(token='[', start_idx=4284, end_idx=4285),\n",
       " Token(token='*', start_idx=4285, end_idx=4286),\n",
       " Token(token='*', start_idx=4286, end_idx=4287),\n",
       " Token(token='2174', start_idx=4287, end_idx=4291),\n",
       " Token(token='-', start_idx=4291, end_idx=4292),\n",
       " Token(token='5', start_idx=4292, end_idx=4293),\n",
       " Token(token='-', start_idx=4293, end_idx=4294),\n",
       " Token(token='17', start_idx=4294, end_idx=4296),\n",
       " Token(token='*', start_idx=4296, end_idx=4297),\n",
       " Token(token='*', start_idx=4297, end_idx=4298),\n",
       " Token(token=']', start_idx=4298, end_idx=4299),\n",
       " Token(token='12:00AM', start_idx=4300, end_idx=4307),\n",
       " Token(token='BLOOD', start_idx=4308, end_idx=4313),\n",
       " Token(token='PT-31.2', start_idx=4314, end_idx=4321),\n",
       " Token(token='*', start_idx=4321, end_idx=4322),\n",
       " Token(token='PTT-28.6', start_idx=4323, end_idx=4331),\n",
       " Token(token='INR(PT)-3.1', start_idx=4332, end_idx=4343),\n",
       " Token(token='*', start_idx=4343, end_idx=4344),\n",
       " Token(token='[', start_idx=4345, end_idx=4346),\n",
       " Token(token='*', start_idx=4346, end_idx=4347),\n",
       " Token(token='*', start_idx=4347, end_idx=4348),\n",
       " Token(token='2174', start_idx=4348, end_idx=4352),\n",
       " Token(token='-', start_idx=4352, end_idx=4353),\n",
       " ...]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('token', 'start_idx', 'end_idx')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [token, start_idx, end_idx]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df = pd.DataFrame(tokens)\n",
    "tokens_df[tokens_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation(token='this', start_idx=0, end_idx=4, tag='B-Reason')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(annotations).duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admission</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  start_idx  end_idx\n",
       "0  Admission          0        9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df[tokens_df.start_idx==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>tag</th>\n",
       "      <th>flag_x</th>\n",
       "      <th>flag_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [token, start_idx, end_idx, tag, flag_x, flag_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ehr = EHR(tokens, annotations, \"1\")\n",
    "combined = ehr.write()\n",
    "combined[combined.flag_y.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>tag</th>\n",
       "      <th>flag_x</th>\n",
       "      <th>flag_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prochlorperazine</td>\n",
       "      <td>166</td>\n",
       "      <td>182</td>\n",
       "      <td>B-Drug</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heparin</td>\n",
       "      <td>185</td>\n",
       "      <td>192</td>\n",
       "      <td>B-Drug</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agents</td>\n",
       "      <td>193</td>\n",
       "      <td>199</td>\n",
       "      <td>I-Drug</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthracycline</td>\n",
       "      <td>506</td>\n",
       "      <td>519</td>\n",
       "      <td>B-Drug</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardiomyopathy</td>\n",
       "      <td>528</td>\n",
       "      <td>542</td>\n",
       "      <td>B-ADE</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>acid</td>\n",
       "      <td>25157</td>\n",
       "      <td>25161</td>\n",
       "      <td>I-Reason</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>levels</td>\n",
       "      <td>25162</td>\n",
       "      <td>25168</td>\n",
       "      <td>I-Reason</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>were</td>\n",
       "      <td>25169</td>\n",
       "      <td>25173</td>\n",
       "      <td>I-Reason</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>high</td>\n",
       "      <td>25174</td>\n",
       "      <td>25178</td>\n",
       "      <td>I-Reason</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>coumadin</td>\n",
       "      <td>25450</td>\n",
       "      <td>25458</td>\n",
       "      <td>B-Drug</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                token  start_idx  end_idx       tag flag_x flag_y\n",
       "0    Prochlorperazine        166      182    B-Drug      A      T\n",
       "1             Heparin        185      192    B-Drug      A      T\n",
       "2              Agents        193      199    I-Drug      A      T\n",
       "3       anthracycline        506      519    B-Drug      A      T\n",
       "4      cardiomyopathy        528      542     B-ADE      A      T\n",
       "..                ...        ...      ...       ...    ...    ...\n",
       "419              acid      25157    25161  I-Reason      A      T\n",
       "420            levels      25162    25168  I-Reason      A      T\n",
       "421              were      25169    25173  I-Reason      A      T\n",
       "422              high      25174    25178  I-Reason      A      T\n",
       "423          coumadin      25450    25458    B-Drug      A      T\n",
       "\n",
       "[424 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_start_indexes1 = []\n",
    "for i in re.finditer(r'(?!.*[\\d]+)\\. [A-Z]', text):\n",
    "    para_start_indexes1.append(i.span())\n",
    "    \n",
    "para_start_indexes2 = []\n",
    "for i in re.finditer(r'(?![\\d]+)\\. [A-Z]', text):\n",
    "    para_start_indexes2.append(i.span())\n",
    "    \n",
    "    \n",
    "para_start_indexes3 = []\n",
    "for i in re.finditer(r'(\\n[\\n]+)', text):\n",
    "    para_start_indexes3.append(i.span())\n",
    "    \n",
    "len(para_start_indexes1), len(para_start_indexes2), len(para_start_indexes3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_idxs = [idxs for idxs in para_start_indexes2 if idxs not in para_start_indexes1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (start, end) in enumerate(para_start_indexes3):\n",
    "    print(f\"{'='*50}{i}{'='*50}\")\n",
    "    window = 10\n",
    "    idx = (end - start + 2*window)//2\n",
    "    \n",
    "    string = text[start-window:end+window]\n",
    "    \n",
    "    ex = [{\"text\": string, \n",
    "       \"ents\": [{\"start\": idx-1, \"end\": idx+1, \"label\": \"O\"}],\n",
    "       \"title\": None}]\n",
    "    html = displacy.render(ex, style=\"ent\", manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_start_indexes3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[511].end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_start_indexes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_start_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while para_start_indexes:\n",
    "    idxs = para_start_indexes.pop(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_start_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(tokens, text, seq_length):\n",
    "    \n",
    "    start = 0 \n",
    "    end = start + seq_length\n",
    "    \n",
    "    tokens[end]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[64:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in re.finditer(pattern=r'. [A-Z]', string=\"This is a sentence. Where? exactly. Hello\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\n [A-Z]', \"This is a text. \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner_ehr",
   "language": "python",
   "name": "ner_ehr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
